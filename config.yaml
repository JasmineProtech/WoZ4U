pepper_ips:  # Entry in dropdown menu will be create for every list item
  - 130.239.182.11  # pepper ip address, should be reachable from network where interface is hosted.
  - 192.168.10.2
  - 192.168.10.3
  - 192.168.10.4

# ALL CONCRETE ACTIONS (BUTTONS IN THE UI) CAN GET THE "key_comb" FIELD.
# PROVIDING A LIST WILL BIND THE KEYS IN THAT LAST TO THE CONCRETE ACTION TO EXECUTE
# VALID COMBINATIONS ARE CONTROL + ANY VALID JS KEY_VALUE
# full list here: https://developer.mozilla.org/de/docs/Web/API/KeyboardEvent/key/Key_Values
# example flag: key_comb: ["Control", "1"]  <-- Binds Control + 1 keyboard shortcut to an action
# ARROW KEY MAY NOT BE USED, AS THEY ARE ALREADY IN USE TO DRIVE PEPPER AND CONTROL THE HEAD AND HIP!!

messages: 
  # Avoid special characters in messages, this can break the backend.
  # EG: Instead if a ', put &apos; into the message, which is the HTML symbol for the apostroph
  -
    short: Title # This will be shown in the GUI
    full_text: This is the complete message that we want the pepper robot to say. # This will be the spoken message
    key_comb: ["Control", "1"]  # keyboard shortcut for this action
  -
    short: Hello
    full_text: Hello, Im pepper.
    key_comb: ["Control", "2"]
  -
    short: Insult
    full_text: Here are the test results; you are a horrible person.
    key_comb: ["Control", "3"]
  -
    short: Compliment
    full_text: Ive always thought you are virtually perfect.
    key_comb: ["Control", "4"]
  -
    short: Blah
    full_text: blah blah blah blah blah, blah blah blah, blah.
    key_comb: ["Control", "5"]

image_root_location: /static/imgs/  # place image files here, on host machine

images:
  -
    title: Default img
    file_name: climate_change.jpg
    is_default_img: True  # image with this flag will be displayed on connect
  - 
    title: Landscape
    file_name: landscape.jpg
  -
    title: Umea logo
    file_name: umea_logo.png
  -
    title: Arrow keys
    file_name: arrow_keys.png
  - 
    title: Sound playing
    file_name: sound_playing.png

audio_files:
  # These have to be stored directly on the Pepper, it's the only way properly supported by the naoqi API :/
  # Button will be created for every item in the list
  -
    title: Imperial March
    location: /home/nao/sound_files/ImperialMarch60.wav  # absolute path on the Pepper
    key_comb: ["Control", "q"]
  - 
    title: Cantina band
    location: /home/nao/sound_files/CantinaBand60.wav
    key_comb: ["Control", "w"]
  -
    title: Star Wars
    location: /home/nao/sound_files/StarWars60.wav
    key_comb: ["Control", "e"]
  - 
    title: Pink Panther
    location: /home/nao/sound_files/PinkPanther60.wav
    key_comb: ["Control", "r"]
  -
    title: Elephant walking
    location: /home/nao/sound_files/BabyElephantWalk60.wav
    key_comb: ["Control", "t"]

animated_speech:
    # Button will be created for every item in the list
  -
    title: Over here
    string: "Hello! ^start(animations/Stand/Gestures/Hey_1) I am over here. ^wait(animations/Stand/Gestures/Hey_1)"
    tooltip: blah
  -
    title: I am this tall
    string: "Look at me! ^run(animations/Stand/Gestures/ShowSky_8) I am this tall!"
    tooltip: blah
  -
    title: Point far
    string: "^start(animations/Stand/Gestures/Far_3) Theyre taking the hobbits to Isengard! ^wait(animations/Stand/Gestures/Far_3) "
    tooltip: blah
  -
    title: Show tablet
    string: "^start(ShowTablet_3) Look at my tablet. ^wait(ShowTablet_3)"
    tooltip: blah

gestures: # Buttons will be created for every item in the list
  -
    title: "Yes"  # Label for button
    gesture: "animations/Stand/Gestures/Yes_1"  # Gesture to execute
    tooltip: "Yes_1 gesture"  # Tooltip for buton
  -
    title: "No"
    gesture: "animations/Stand/Gestures/No_1"
    tooltip: "No_1 gesture"
  -
    title: "Wave"
    gesture: "animations/Stand/Gestures/Hey_3"
    tooltip: blah
  -
    title: "Me"
    gesture: "animations/Stand/Gestures/Me_1"
    tooltip: blah
  -
    title: "You"
    gesture: "animations/Stand/Gestures/You_1"
    tooltip: blah
  -
    title: "Embarrassed"
    gesture: "animations/Stand/Emotions/Neutral/Embarrassed_1"
    tooltip: blah
  -
    title: "Happy"
    gesture: "animations/Stand/Emotions/Positive/Happy_4"
    tooltip: blah

camera_save_dir: record_imgs  # relative folder on host machine, images form camera feed will be saved here
audio_save_dir: /home/nao/ # absolute path on pepper robot, you'll have scp it from there yourself

# AUTONOMOUS LIFE SETTINGS
# Leave as empty string to not leave value as is on connection to robot
# values must be valid for respective set methods in naoqi API...
autonomous_life_config:
  autonomous_state: "solitary"
  tangential_collision: ""
  orthogonal_collision: ""
  blinking: False  # can interfere with manual eye control...
  basic_awareness: False  # gets enabled by default if pepper enters solitary or interactive state...
  engagement_mode: ""
  head_breathing: False  # I would advise always having this disabled, conflicts with manual head control...
  arms_breathing: True
  body_breathing: True
  legs_breathing: True
  # TODO: ADD listening/speaking movements

# LED SETTINGS
# Putting empty strings as values leave the settings as is on connect
led_settings:
  intensity: 0.1
  color: # color for eye leds. API requires rgb values in range [0-1]
    red: 0
    green: 1.0
    blue: 0